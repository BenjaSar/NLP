{"cells":[{"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","# Natural Language Processing\n","\n","## LSTM Bot QA\n"]},{"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)\n"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"bDFC0I3j9oFD"},"outputs":[],"source":["!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"cq3YXak9sGHd"},"outputs":[],"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchinfo in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (1.8.0)\n"]}],"source":["!pip3 install torchinfo\n","from torchinfo import summary"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["cuda = torch.cuda.is_available()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["import os\n","import platform\n","\n","if os.access('torch_helpers.py', os.F_OK) is False:\n","    if platform.system() == 'Windows':\n","        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n","    else:\n","        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["def sequence_acc(y_pred, y_test):\n","    y_pred_tag = y_pred.data.max(dim=-1, keepdim=True)[1]\n","    y_test_tag = y_test.data.max(dim=-1, keepdim=True)[1]\n","\n","    batch_size = y_pred_tag.shape[0]\n","    batch_acc = torch.zeros(batch_size)\n","    for b in range(batch_size):\n","        correct_results_sum = (y_pred_tag[b] == y_test_tag[b]).sum().float()\n","        batch_acc[b] = correct_results_sum / y_pred_tag[b].shape[0]\n","\n","    correct_results_sum = batch_acc.sum().float()\n","    acc = correct_results_sum / batch_size\n","    return acc\n","\n","\n","def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n","    # Defino listas para realizar graficas de los resultados\n","    train_loss = []\n","    train_accuracy = []\n","    valid_loss = []\n","    valid_accuracy = []\n","\n","    # Defino mi loop de entrenamiento\n","\n","    for epoch in range(epochs):\n","\n","        epoch_train_loss = 0.0\n","        epoch_train_accuracy = 0.0\n","\n","        for train_encoder_input, train_decoder_input, train_target in train_loader:\n","            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n","            # los va acumulando\n","            optimizer.zero_grad()\n","\n","            output = model(train_encoder_input.to(device),\n","                           train_decoder_input.to(device))\n","\n","            # Computo el error de la salida comparando contra las etiquetas\n","            # por cada token en cada batch (sequence_loss)\n","            loss = 0\n","            for t in range(train_decoder_input.shape[1]):\n","                loss += criterion(output[:, t, :], train_target[:, t, :])\n","\n","            # Almaceno el error del batch para luego tener el error promedio de la epoca\n","            epoch_train_loss += loss.item()\n","\n","            # Computo el nuevo set de gradientes a lo largo de toda la red\n","            loss.backward()\n","\n","            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n","            optimizer.step()\n","\n","            # Calculo el accuracy del batch\n","            accuracy = sequence_acc(output, train_target)\n","            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n","            epoch_train_accuracy += accuracy.item()\n","\n","        # Calculo la media de error para la epoca de entrenamiento.\n","        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n","        epoch_train_loss = epoch_train_loss / len(train_loader)\n","        train_loss.append(epoch_train_loss)\n","        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n","        train_accuracy.append(epoch_train_accuracy)\n","\n","        # Realizo el paso de validación computando error y accuracy, y\n","        # almacenando los valores para imprimirlos y graficarlos\n","        # valid_encoder_input, valid_decoder_input, valid_target = iter(valid_loader).next()\n","\n","        # valid_data, valid_target = iter(valid_loader).next()\n","        data_iter = iter(valid_loader)\n","        valid_encoder_input, valid_decoder_input, valid_target = next(\n","            data_iter)\n","        output = model(valid_encoder_input.to(device),\n","                       valid_decoder_input.to(device))\n","\n","        epoch_valid_loss = 0\n","        for t in range(train_decoder_input.shape[1]):\n","            epoch_valid_loss += criterion(output[:, t, :],\n","                                          valid_target[:, t, :])\n","        epoch_valid_loss = epoch_valid_loss.item()\n","\n","        valid_loss.append(epoch_valid_loss)\n","\n","        # Calculo el accuracy de la epoch\n","        epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n","        valid_accuracy.append(epoch_valid_accuracy)\n","\n","        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n","\n","    history = {\n","        \"loss\": train_loss,\n","        \"accuracy\": train_accuracy,\n","        \"val_loss\": valid_loss,\n","        \"val_accuracy\": valid_accuracy,\n","    }\n","    return history"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Datos\n"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"RHNkUaPp6aYq"},"outputs":[{"name":"stdout","output_type":"stream","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Download the dataset\n","import os\n","import gdown\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"WZy1-wgG-Rp7"},"outputs":[],"source":["# dataset_file\n","import json\n","\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f)  # the data variable will be a dictionary"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"ue5qd54S-eew"},"outputs":[{"data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["# Observing the disponibles fields in every line of the dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"jHBRAXPl-3dz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows used: 6033\n"]}],"source":["chat_in = []\n","chat_out = []\n","\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 30\n","\n","\n","def clean_text(txt):\n","    txt = txt.lower()\n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","\n","    return txt\n","\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","\n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Number of rows used:\", len(input_sentences))"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"07L1qj8pC_l6"},"outputs":[{"data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocessing\n","\n","Realizar el preprocesamiento necesario para obtener:\n","\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# Define the maximun number of words\n","MAX_VOCABULARY_SIZE = 8000"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["from torch_helpers import Tokenizer\n","\n","\n","# Create tokenizer for the input text and fit it to them\n","tokenizer_inputs = Tokenizer(num_words=MAX_VOCABULARY_SIZE)\n","tokenizer_inputs.fit_on_texts(input_sentences)\n","\n","# Tokenize and transform input texts to sequence of integers\n","input_integer_seq = tokenizer_inputs.texts_to_sequences(input_sentences)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Words in the vocabulary 1799\n","The longest sentence 9\n"]}],"source":["word2idx_inputs = tokenizer_inputs.word_index\n","print('Words in the vocabulary', len(word2idx_inputs))\n","\n","# Calculate the max length\n","max_input_len = max(len(sentence) for sentence in input_integer_seq)\n","print('The longest sentence', max_input_len)"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[22]\n"]}],"source":["# Check the tokenization\n","print(input_integer_seq[200])"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Create tokenizer for the outpu text and fit it to them\n","# output_tokenizer = Tokenizer(num_words=MAX_VOCABULARY_SIZE, filters='')\n","output_tokenizer = Tokenizer(\n","    num_words=MAX_VOCABULARY_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n","\n","output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1806 unique output tokens.\n"]}],"source":["# Get the word to index mapping for output answer\n","word2idx_outputs = output_tokenizer.word_index\n","print('Found %s unique output tokens.' % len(word2idx_outputs))"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n","output_input_integer_seq = output_tokenizer.texts_to_sequences(\n","    output_sentences_inputs)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The longest sentence in the output 10\n"]}],"source":["# Calculate the max length for the ouput\n","max_output_len = max(len(sentence) for sentence in output_integer_seq)\n","print('The longest sentence in the output', max_output_len)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1807\n"]}],"source":["# One is added to include the toke of unknown word\n","number_word_output = min(len(word2idx_outputs) + 1, MAX_VOCABULARY_SIZE)\n","print(number_word_output)"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoder input sequences shape:  (6033, 9)\n","Decoder input sequences shape:  (6033, 10)\n"]}],"source":["from torch_helpers import pad_sequences\n","\n","encoder_input_seq = pad_sequences(input_integer_seq, maxlen=max_input_len)\n","print('Encoder input sequences shape: ', encoder_input_seq.shape)\n","\n","decoder_input_seq = pad_sequences(\n","    output_integer_seq, maxlen=max_output_len, padding='post')\n","print('Decoder input sequences shape: ', decoder_input_seq.shape)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["max_output_len"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([6033, 10])"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["# from keras.utils.np_utils import to_categorical\n","decoder_output_seq = pad_sequences(\n","    output_integer_seq, maxlen=max_output_len, padding='post')\n","decoder_output_seq.shape\n","\n","torch.from_numpy(decoder_output_seq).shape"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"data":{"text/plain":["(6033, 10)"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["decoder_output_seq.shape"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder_input_size: 9\n","decoder_input_size: 10\n","Output dim 1807\n"]}],"source":["class Data(Dataset):\n","    def __init__(self, encoder_input, decoder_input, decoder_output):\n","        # Transforming the numpy array to tensors.\n","        # Pytorch receives 32bits inputs\n","        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n","        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n","        # Transformar los datos a oneHotEncoding\n","        # la loss function esperan la salida float\n","        self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(\n","            torch.int64), num_classes=number_word_output).float()\n","\n","        self.len = self.decoder_outputs.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n","\n","    def __len__(self):\n","        return self.len\n","\n","\n","data_set = Data(encoder_input_seq, decoder_input_seq, decoder_output_seq)\n","\n","encoder_input_size = data_set.encoder_inputs.shape[1]\n","print(\"encoder_input_size:\", encoder_input_size)\n","\n","decoder_input_size = data_set.decoder_inputs.shape[1]\n","print(\"decoder_input_size:\", decoder_input_size)\n","\n","output_dim = data_set.decoder_outputs.shape[2]\n","print(\"Output dim\", output_dim)"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sizing of the training set: 4827\n","Sizing of the validation set: 1206\n"]}],"source":["torch.manual_seed(42)\n","valid_set_size = int(data_set.len * 0.2)\n","train_set_size = data_set.len - valid_set_size\n","\n","train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n","valid_set = torch.utils.data.Subset(\n","    data_set, range(train_set_size, data_set.len))\n","\n","print(\"Sizing of the training set:\", len(train_set))\n","print(\"Sizing of the validation set:\", len(valid_set))\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_set, batch_size=32, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_set, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparing the embeddings\n","\n","Using the embeddings of Glove or Fastext to transform the input tokens to vectors\n","\n","Based on subject Natural Language Processing - University of Buenos Aires - Embedded Systems Laboratory\n"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The embeddings gloveembedding.pkl have been downloaded yet\n"]}],"source":["# Download the embeddings\n","import os\n","import gdown\n","if os.access('gloveembedding.pkl', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download'\n","    output = 'gloveembedding.pkl'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"The embeddings gloveembedding.pkl have been downloaded yet\")"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["import logging\n","import os\n","from pathlib import Path\n","from io import StringIO\n","import pickle\n","\n","\n","class WordsEmbeddings(object):\n","    logger = logging.getLogger(__name__)\n","\n","    def __init__(self):\n","        # load the embeddings\n","        words_embedding_pkl = Path(self.PKL_PATH)\n","        if not words_embedding_pkl.is_file():\n","            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n","            assert words_embedding_txt.is_file(), 'Words embedding not available'\n","            embeddings = self.convert_model_to_pickle()\n","        else:\n","            embeddings = self.load_model_from_pickle()\n","        self.embeddings = embeddings\n","        # build the vocabulary hashmap\n","        index = np.arange(self.embeddings.shape[0])\n","        # Dictionary to translate of the embeeding to word idx\n","        self.word2idx = dict(zip(self.embeddings['word'], index))\n","        self.idx2word = dict(zip(index, self.embeddings['word']))\n","\n","    def get_words_embeddings(self, words):\n","        words_idxs = self.words2idxs(words)\n","        return self.embeddings[words_idxs]['embedding']\n","\n","    def words2idxs(self, words):\n","        return np.array([self.word2idx.get(word, -1) for word in words])\n","\n","    def idxs2words(self, idxs):\n","        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n","\n","    def load_model_from_pickle(self):\n","        self.logger.debug(\n","            'loading words embeddings from pickle {}'.format(\n","                self.PKL_PATH\n","            )\n","        )\n","        max_bytes = 2**28 - 1  # 256MB\n","        bytes_in = bytearray(0)\n","        input_size = os.path.getsize(self.PKL_PATH)\n","        with open(self.PKL_PATH, 'rb') as f_in:\n","            for _ in range(0, input_size, max_bytes):\n","                bytes_in += f_in.read(max_bytes)\n","        embeddings = pickle.loads(bytes_in)\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","    def convert_model_to_pickle(self):\n","        # create a numpy strctured array:\n","        # word     embedding\n","        # U50      np.float32[]\n","        # word_1   a, b, c\n","        # word_2   d, e, f\n","        # ...\n","        # word_n   g, h, i\n","        self.logger.debug(\n","            'converting and loading words embeddings from text file {}'.format(\n","                self.WORD_TO_VEC_MODEL_TXT_PATH\n","            )\n","        )\n","        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n","                     ('embedding', np.float32, (self.N_FEATURES,))]\n","        structure = np.dtype(structure)\n","        # load numpy array from disk using a generator\n","        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n","            embeddings_gen = (\n","                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n","                if len(line.split()[1:]) == self.N_FEATURES\n","            )\n","            embeddings = np.fromiter(embeddings_gen, structure)\n","        # add a null embedding\n","        null_embedding = np.array(\n","            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n","            dtype=structure\n","        )\n","        embeddings = np.concatenate([embeddings, null_embedding])\n","        # dump numpy array to disk using pickle\n","        max_bytes = 2**28 - 1  # 256MB\n","        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n","        with open(self.PKL_PATH, 'wb') as f_out:\n","            for idx in range(0, len(bytes_out), max_bytes):\n","                f_out.write(bytes_out[idx:idx+max_bytes])\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","\n","class GloveEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n","    PKL_PATH = 'gloveembedding.pkl'\n","    N_FEATURES = 50\n","    # N_FEATURES = 51\n","    WORD_MAX_SIZE = 60\n","\n","\n","class FasttextEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n","    PKL_PATH = 'fasttext.pkl'\n","    N_FEATURES = 300\n","    WORD_MAX_SIZE = 60"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["model_embeddings = GloveEmbeddings()"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["# model_embeddings = FasttextEmbeddings()"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["preparing embedding matrix...\n","number of null word embeddings: 38\n"]}],"source":["# Making the matrix embedding of the sequences\n","print('preparing embedding matrix...')\n","embed_dim = model_embeddings.N_FEATURES\n","words_not_found = []\n","\n","# The word index comes from tokenizer\n","\n","nb_words = min(MAX_VOCABULARY_SIZE, len(word2idx_inputs))  # vocab_size\n","embedding_matrix = np.zeros((nb_words, embed_dim))\n","for word, i in word2idx_inputs.items():\n","    if i >= nb_words:\n","        continue\n","    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n","    if (embedding_vector is not None) and len(embedding_vector) > 0:\n","\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        # words not found in embedding index will be all-zeros.\n","        words_not_found.append(word)\n","\n","print('number of null word embeddings:', np.sum(\n","    np.sum(embedding_matrix**2, axis=1) == 0))"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/plain":["(1799, 50)"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["# The embedding size\n","embedding_matrix.shape"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/plain":["1799"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["nb_words"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"data":{"text/plain":["(1799, 50)"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix.shape"]},{"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Training the model\n","\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase.\n"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"data":{"text/plain":["9"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["max_input_len"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Seq2Seq                                  [1, 10, 1807]             --\n","├─Encoder: 1-1                           [1, 1, 128]               --\n","│    └─Embedding: 2-1                    [1, 9, 50]                (89,950)\n","│    └─LSTM: 2-2                         [1, 9, 128]               92,160\n","├─Decoder: 1-2                           [1, 1807]                 --\n","│    └─Embedding: 2-3                    [1, 1, 50]                90,350\n","│    └─LSTM: 2-4                         [1, 1, 128]               92,160\n","│    └─Linear: 2-5                       [1, 1807]                 233,103\n","│    └─Softmax: 2-6                      [1, 1807]                 --\n","├─Decoder: 1-3                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-7                    [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-8                         [1, 1, 128]               (recursive)\n","│    └─Linear: 2-9                       [1, 1807]                 (recursive)\n","│    └─Softmax: 2-10                     [1, 1807]                 --\n","├─Decoder: 1-4                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-11                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-12                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-13                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-14                     [1, 1807]                 --\n","├─Decoder: 1-5                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-15                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-16                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-17                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-18                     [1, 1807]                 --\n","├─Decoder: 1-6                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-19                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-20                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-21                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-22                     [1, 1807]                 --\n","├─Decoder: 1-7                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-23                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-24                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-25                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-26                     [1, 1807]                 --\n","├─Decoder: 1-8                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-27                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-28                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-29                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-30                     [1, 1807]                 --\n","├─Decoder: 1-9                           [1, 1807]                 (recursive)\n","│    └─Embedding: 2-31                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-32                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-33                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-34                     [1, 1807]                 --\n","├─Decoder: 1-10                          [1, 1807]                 (recursive)\n","│    └─Embedding: 2-35                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-36                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-37                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-38                     [1, 1807]                 --\n","├─Decoder: 1-11                          [1, 1807]                 (recursive)\n","│    └─Embedding: 2-39                   [1, 1, 50]                (recursive)\n","│    └─LSTM: 2-40                        [1, 1, 128]               (recursive)\n","│    └─Linear: 2-41                      [1, 1807]                 (recursive)\n","│    └─Softmax: 2-42                     [1, 1807]                 --\n","==========================================================================================\n","Total params: 597,723\n","Trainable params: 507,773\n","Non-trainable params: 89,950\n","Total mult-adds (M): 5.08\n","==========================================================================================\n","Input size (MB): 0.46\n","Forward/backward pass size (MB): 0.17\n","Params size (MB): 2.39\n","Estimated Total Size (MB): 3.02\n","=========================================================================================="]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        # num_embeddings = vocab_size, it is defined by the tokenizer \n","        # embedding_dim = 50 --> The dimension of the embeddings used\n","        self.lstm_size = 128\n","        self.num_layers = 1\n","        self.embedding_dim = embed_dim\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n","        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n","        # Marking as untrainable layer (freeze)\n","        self.embedding.weight.requires_grad = False\n","        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n","                            num_layers=self.num_layers)  # LSTM layer\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        lstm_output, (ht, ct) = self.lstm(out)\n","        return (ht, ct)\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, output_dim):\n","        super().__init__()\n","        # num_embeddings = vocab_size, it is defined by the tokenizer\n","        # embedding_dim = 50 --> The dimension of the embeddings used\n","        self.lstm_size = 128\n","        self.num_layers = 1\n","        self.embedding_dim = embed_dim\n","        self.output_dim = output_dim\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n","                            num_layers=self.num_layers)  # LSTM layer\n","        # Fully connected layer\n","        self.fc1 = nn.Linear(in_features=self.lstm_size,\n","                             out_features=self.output_dim)\n","\n","        self.softmax = nn.Softmax(dim=1)  # normalize in dim 1\n","\n","    def forward(self, x, prev_state):\n","        out = self.embedding(x)\n","        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n","        # take last output (last seq)\n","        out = self.softmax(self.fc1(lstm_output[:, -1, :]))\n","        return out, (ht, ct)\n","\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","        assert encoder.lstm_size == decoder.lstm_size, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.num_layers == decoder.num_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","\n","    def forward(self, encoder_input, decoder_input):\n","        batch_size = decoder_input.shape[0]\n","        decoder_input_len = decoder_input.shape[1]\n","        vocab_size = self.decoder.output_dim\n","\n","        # Tensor to save the output\n","        # (batch_size, sentence_len, one_hot_size)\n","        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n","\n","        # The last hidden state of the encoder, the first hidden state of the decoder\n","        prev_state = self.encoder(encoder_input)\n","\n","        # In the first iteration takes the first token target (<sos>)\n","        input = decoder_input[:, 0:1]\n","\n","        for t in range(decoder_input_len):\n","            # t --> token index\n","\n","            # We use the \"teacher forcing\" method, it mean that during the training  we won't feedback the output of the decoder and will use  the right token wich follows on target\n","            input = decoder_input[:, t:t+1]\n","\n","            # Input every token embedding, one by one together with the hidden state \n","            # Receiving the decoder output (softmax)\n","            output, prev_state = self.decoder(input, prev_state)\n","            top1 = output.argmax(1).view(-1, 1)\n","\n","            # Sino se usará \"teacher forcing\" habría que descomentar\n","            # esta linea.\n","            # Hay ejemplos dandos vuelta en donde se utilza un random\n","            # para ver en cada vuelta que técnica se aplica\n","            # input = top1\n","\n","            # Saving the output(softmax)\n","            outputs[:, t, :] = output\n","\n","        return outputs\n","\n","\n","encoder = Encoder(vocab_size=nb_words)\n","if cuda:\n","    encoder.cuda()\n","# decoder --> vocab_size == output_dim --> Because receive and return words in the same vocabulary \n","decoder = Decoder(vocab_size=number_word_output, output_dim=number_word_output)\n","if cuda:\n","    decoder.cuda()\n","\n","model = Seq2Seq(encoder, decoder)\n","if cuda:\n","    model.cuda()\n","\n","# Creating the optimizer for the error function\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n","criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n","\n","summary(model, input_data=(data_set[0:1][0], data_set[0:1][1]))"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/20 - Train loss 67.211 - Train accuracy 0.782 - Valid Loss 67.035 - Valid accuracy 0.797\n","Epoch: 2/20 - Train loss 66.915 - Train accuracy 0.809 - Valid Loss 66.880 - Valid accuracy 0.812\n","Epoch: 3/20 - Train loss 66.867 - Train accuracy 0.814 - Valid Loss 66.789 - Valid accuracy 0.822\n","Epoch: 4/20 - Train loss 66.821 - Train accuracy 0.818 - Valid Loss 66.757 - Valid accuracy 0.825\n","Epoch: 5/20 - Train loss 66.790 - Train accuracy 0.821 - Valid Loss 66.724 - Valid accuracy 0.828\n","Epoch: 6/20 - Train loss 66.760 - Train accuracy 0.824 - Valid Loss 66.739 - Valid accuracy 0.825\n","Epoch: 7/20 - Train loss 66.741 - Train accuracy 0.826 - Valid Loss 66.723 - Valid accuracy 0.828\n","Epoch: 8/20 - Train loss 66.750 - Train accuracy 0.825 - Valid Loss 66.723 - Valid accuracy 0.828\n","Epoch: 9/20 - Train loss 66.745 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 10/20 - Train loss 66.743 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 11/20 - Train loss 66.743 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 12/20 - Train loss 66.742 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 13/20 - Train loss 66.743 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 14/20 - Train loss 66.742 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 15/20 - Train loss 66.742 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 16/20 - Train loss 66.742 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 17/20 - Train loss 66.742 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 18/20 - Train loss 66.740 - Train accuracy 0.826 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 19/20 - Train loss 66.724 - Train accuracy 0.828 - Valid Loss 66.722 - Valid accuracy 0.828\n","Epoch: 20/20 - Train loss 66.724 - Train accuracy 0.828 - Valid Loss 66.722 - Valid accuracy 0.828\n"]}],"source":["history1 = train(model,\n","                 train_loader,\n","                 valid_loader,\n","                 optimizer,\n","                 criterion,\n","                 epochs=20\n","                 )"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["epoch_count = range(1, len(history1['accuracy']) + 1)\n","sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n","sns.lineplot(x=epoch_count,  y=history1['val_accuracy'], label='valid')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inference\n","\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder.\n"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["# Based on the subject Natural Language Processing - Embedded Systems Laboratory - UBA\n","\n","# Make the conversor from index to word:\n","idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n","idx2word_target = {v:k for k, v in word2idx_outputs.items()}"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input:  I am a clean eater\n","Vectorial representations of tokens of ids [1, 9, 5]\n","Vector padding [[0 0 0 0 0 0 1 9 5]]\n","Word output for\n"]}],"source":["input_test = 'I am a clean eater'\n","print('Input: ', input_test)\n","integer_seq_test = tokenizer_inputs.texts_to_sequences([input_test])[0]\n","print('Vectorial representations of tokens of ids', integer_seq_test)\n","encoder_seq_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n","print(\"Vector padding\", encoder_seq_test)\n","encoder_seq_test_tensor = torch.from_numpy(encoder_seq_test.astype(np.int32))\n","\n","prev_state = model.encoder(encoder_seq_test_tensor.to(device))\n","\n","# Initialize input sequence to the decoder as <sos>\n","target_seq = np.zeros((1, 1))\n","target_seq[0, 0] = word2idx_outputs['<sos>']\n","target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n","\n","output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n","\n","top1 = output.argmax(1).view(-1, 1)\n","idx = int(top1.cpu())\n","\n","word = idx2word_target[idx]\n","print(\"Word output\", word)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["def chat_bot_qa(input_seq):\n","    prev_state = model.encoder(encoder_seq_test_tensor.to(device))\n","\n","    # Initialize input sequence to the decoder as <sos>\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n","\n","    eos = word2idx_outputs['<eos>']\n","\n","    output_sentence = []\n","    \n","    for _ in range(max_output_len):\n","        # Prediction of the next element\n","        output, new_prev_state = model.decoder(\n","            target_seq_tensor.to(device), prev_state)\n","        top1 = output.argmax(1).view(-1, 1)\n","        idx = int(top1.cpu())\n","\n","        # If it is  \"end of sentece <eos>\" it will end\n","        if eos == idx:\n","            break\n","\n","        # Transform idx to word\n","        word = ''\n","        if idx > 0:\n","            word = idx2word_target[idx]\n","            output_sentence.append(word)\n","\n","        # Actualizar los estados dado la ultimo prediccion\n","        prev_state = new_prev_state\n","\n","        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n","        target_seq_tensor = top1\n","\n","    return ' '.join(output_sentence)\n","    #return ','.join([str(s) for s in output_sentence])"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input: by having sex\n","Response: for for for for for for for for for for\n","-\n","Input: hi\n","Response: for for for for for for for for for for\n","-\n","Input: hii\n","Response: for for for for for for for for for for\n","-\n","Input: hi there how are you \n","Response: for for for for for for for for for for\n","-\n","Input: hello how are you doing \n","Response: for for for for for for for for for for\n","-\n","Input: told you earlier engineering\n","Response: for for for for for for for for for for\n"]}],"source":["for i in range(0,6):\n","    i = np.random.choice(len(input_sentences))\n","    input_seq = encoder_input_seq[i:i+1]\n","    encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n","    chat_bot = chat_bot_qa(encoder_sequence_test_tensor)\n","    print('-')\n","    print('Input:', input_sentences[i])\n","    print('Response:', chat_bot)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
