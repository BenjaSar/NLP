{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZd5yLnnHOK0"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Natural Language Processing\n",
    "## Embedding custom with Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lFToQs5FK5uZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (5.9.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nbformat) (2.18.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nbformat) (5.3.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\fsiof\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->nbformat) (3.6.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\fsiof\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from jupyter-core->nbformat) (305.1)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import platform\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "!pip install nbformat \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g07zJxG7H9vG"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ticoqYD1Z3I7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ARTICLE LINK</th>\n",
       "      <th>PUBLISHED DATE (UTC)</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>IMAGE URL</th>\n",
       "      <th>VIDEO URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Independent Belarusian Filmmakers Condemn Rus...</td>\n",
       "      <td>https://www.hollywoodreporter.com/news/general...</td>\n",
       "      <td>01-03-2022 13:53:11</td>\n",
       "      <td>Scott Roxborough</td>\n",
       "      <td>The Hollywood Reporter</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>Top</td>\n",
       "      <td>English</td>\n",
       "      <td>A group of Belarusian filmmakers, many of whom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"UK bars stop pouring Russian vodka over Ukrai...</td>\n",
       "      <td>https://ca.sports.yahoo.com/news/uk-bars-stop-...</td>\n",
       "      <td>01-03-2022 13:53:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yahoo! News</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Sports</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Iggy Pop and Bring Me The Horizon cancel show...</td>\n",
       "      <td>https://www.nme.com/news/music/iggy-pop-and-br...</td>\n",
       "      <td>01-03-2022 13:50:51</td>\n",
       "      <td>Tom Skinner</td>\n",
       "      <td>Nme</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>English</td>\n",
       "      <td>\"We will be using our platform and voice to do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"British father makes it to wife and son after...</td>\n",
       "      <td>https://ca.sports.yahoo.com/news/british-fathe...</td>\n",
       "      <td>01-03-2022 13:50:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yahoo! News</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Sports</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Russia, Ukraine to hold second round of talks...</td>\n",
       "      <td>https://nationalpost.com/pmn/news-pmn/crime-pm...</td>\n",
       "      <td>01-03-2022 13:50:09</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>National Post</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Top</td>\n",
       "      <td>English</td>\n",
       "      <td>MOSCOW — The second round of Russia-Ukraine ta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "0  \"Independent Belarusian Filmmakers Condemn Rus...   \n",
       "1  \"UK bars stop pouring Russian vodka over Ukrai...   \n",
       "2  \"Iggy Pop and Bring Me The Horizon cancel show...   \n",
       "3  \"British father makes it to wife and son after...   \n",
       "4  \"Russia, Ukraine to hold second round of talks...   \n",
       "\n",
       "                                        ARTICLE LINK PUBLISHED DATE (UTC)  \\\n",
       "0  https://www.hollywoodreporter.com/news/general...  01-03-2022 13:53:11   \n",
       "1  https://ca.sports.yahoo.com/news/uk-bars-stop-...  01-03-2022 13:53:02   \n",
       "2  https://www.nme.com/news/music/iggy-pop-and-br...  01-03-2022 13:50:51   \n",
       "3  https://ca.sports.yahoo.com/news/british-fathe...  01-03-2022 13:50:48   \n",
       "4  https://nationalpost.com/pmn/news-pmn/crime-pm...  01-03-2022 13:50:09   \n",
       "\n",
       "             AUTHOR               PUBLISHER                   COUNTRY  \\\n",
       "0  Scott Roxborough  The Hollywood Reporter  United States Of America   \n",
       "1               NaN             Yahoo! News                    Canada   \n",
       "2       Tom Skinner                     Nme                    Canada   \n",
       "3               NaN             Yahoo! News                    Canada   \n",
       "4           Reuters           National Post                    Canada   \n",
       "\n",
       "        CATEGORY LANGUAGE                                        DESCRIPTION  \\\n",
       "0            Top  English  A group of Belarusian filmmakers, many of whom...   \n",
       "1         Sports  English                                                NaN   \n",
       "2  Entertainment  English  \"We will be using our platform and voice to do...   \n",
       "3         Sports  English                                                NaN   \n",
       "4            Top  English  MOSCOW — The second round of Russia-Ukraine ta...   \n",
       "\n",
       "  IMAGE URL VIDEO URL  \n",
       "0       NaN       NaN  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset \n",
    "df = pd.read_csv('./data/datasets/ukraine.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['AUTHOR', 'PUBLISHER', 'COUNTRY', 'CATEGORY','IMAGE URL', 'VIDEO URL', 'ARTICLE LINK', 'PUBLISHED DATE (UTC)'],  axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Independent Belarusian Filmmakers Condemn Rus...</td>\n",
       "      <td>English</td>\n",
       "      <td>A group of Belarusian filmmakers, many of whom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"UK bars stop pouring Russian vodka over Ukrai...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Iggy Pop and Bring Me The Horizon cancel show...</td>\n",
       "      <td>English</td>\n",
       "      <td>\"We will be using our platform and voice to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"British father makes it to wife and son after...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Russia, Ukraine to hold second round of talks...</td>\n",
       "      <td>English</td>\n",
       "      <td>MOSCOW — The second round of Russia-Ukraine ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE LANGUAGE  \\\n",
       "0  \"Independent Belarusian Filmmakers Condemn Rus...  English   \n",
       "1  \"UK bars stop pouring Russian vodka over Ukrai...  English   \n",
       "2  \"Iggy Pop and Bring Me The Horizon cancel show...  English   \n",
       "3  \"British father makes it to wife and son after...  English   \n",
       "4  \"Russia, Ukraine to hold second round of talks...  English   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0  A group of Belarusian filmmakers, many of whom...  \n",
       "1                                                NaN  \n",
       "2  \"We will be using our platform and voice to do...  \n",
       "3                                                NaN  \n",
       "4  MOSCOW — The second round of Russia-Ukraine ta...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LEpKubK9XzXN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8678\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab94qaFlrA1G"
   },
   "source": [
    "### 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rIsmMWmjrDHd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fSIoF\\AppData\\Local\\Temp\\ipykernel_16816\\655525431.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sentence_tokens.append(text_to_word_sequence(row[0]))\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence_tokens = []\n",
    "\n",
    "for _, row in df[:None].iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CHepi_DGrbhq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['independent',\n",
       "  'belarusian',\n",
       "  'filmmakers',\n",
       "  'condemn',\n",
       "  'russian',\n",
       "  'attack',\n",
       "  'on',\n",
       "  'ukraine'],\n",
       " ['uk',\n",
       "  'bars',\n",
       "  'stop',\n",
       "  'pouring',\n",
       "  'russian',\n",
       "  'vodka',\n",
       "  'over',\n",
       "  'ukraine',\n",
       "  'invasion']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaXV6nlHr5Aa"
   },
   "source": [
    "### 2 - Make the vectors (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OSb0v7h8r7hK"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(\n",
    "                self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i0wnDdv9sJ47"
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=4, window=2,\n",
    "                     vector_size=500, negative=20,\n",
    "                     workers=1, sg=1)  # Skipgram model used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5lTt8wErsf17"
   },
   "outputs": [],
   "source": [
    "# Getting the vocabulary with the tokens\n",
    "w2v_model.build_vocab(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TNc9qt4os5AT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs on the corpus: 8678\n"
     ]
    }
   ],
   "source": [
    "# Number of rows/docs that were found on the corpus\n",
    "print(\"Number of docs on the corpus:\", w2v_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "idw9cHF3tSMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words on the corpus: 3004\n"
     ]
    }
   ],
   "source": [
    "# Number of words that were found on the corpus\n",
    "print(\"Number of different words on the corpus:\", len(w2v_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC9mZ8DPk-UC"
   },
   "source": [
    "### 3 - Training the generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QSp-x0PAsq56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 940333.625\n",
      "Loss after epoch 1: 595356.75\n",
      "Loss after epoch 2: 563742.875\n",
      "Loss after epoch 3: 477715.0\n",
      "Loss after epoch 4: 463087.5\n",
      "Loss after epoch 5: 448274.0\n",
      "Loss after epoch 6: 434185.25\n",
      "Loss after epoch 7: 413847.5\n",
      "Loss after epoch 8: 387345.5\n",
      "Loss after epoch 9: 378619.0\n",
      "Loss after epoch 10: 367636.0\n",
      "Loss after epoch 11: 360916.0\n",
      "Loss after epoch 12: 352929.5\n",
      "Loss after epoch 13: 344158.5\n",
      "Loss after epoch 14: 341064.5\n",
      "Loss after epoch 15: 333487.0\n",
      "Loss after epoch 16: 329588.0\n",
      "Loss after epoch 17: 323880.5\n",
      "Loss after epoch 18: 321504.5\n",
      "Loss after epoch 19: 308553.5\n",
      "Loss after epoch 20: 289718.0\n",
      "Loss after epoch 21: 288234.0\n",
      "Loss after epoch 22: 284819.0\n",
      "Loss after epoch 23: 282222.0\n",
      "Loss after epoch 24: 279191.0\n",
      "Loss after epoch 25: 275927.0\n",
      "Loss after epoch 26: 273783.0\n",
      "Loss after epoch 27: 270874.0\n",
      "Loss after epoch 28: 268648.0\n",
      "Loss after epoch 29: 267758.0\n",
      "Loss after epoch 30: 266163.0\n",
      "Loss after epoch 31: 262696.0\n",
      "Loss after epoch 32: 263121.0\n",
      "Loss after epoch 33: 261754.0\n",
      "Loss after epoch 34: 260832.0\n",
      "Loss after epoch 35: 258810.0\n",
      "Loss after epoch 36: 258105.0\n",
      "Loss after epoch 37: 256861.0\n",
      "Loss after epoch 38: 255585.0\n",
      "Loss after epoch 39: 257227.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2670027, 4116200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the vector generator model\n",
    "w2v_model.train(sentence_tokens,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=40,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddT9NVuNlCAe"
   },
   "source": [
    "### 4 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6cHN9xGLuPEm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accompany', 0.407772421836853),\n",
       " ('enemy', 0.40125957131385803),\n",
       " ('ordered', 0.4002857804298401),\n",
       " ('potent', 0.39729735255241394),\n",
       " ('resists', 0.3934139609336853),\n",
       " ('performances', 0.3930717706680298),\n",
       " ('rogers', 0.3776595890522003),\n",
       " ('bombard', 0.37752583622932434),\n",
       " ('dan', 0.3730834126472473),\n",
       " ('invasion', 0.370007187128067)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that are more related to...:\n",
    "w2v_model.wv.most_similar(positive=[\"russian\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "47HiU5gdkdMq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reveals', -0.06776457279920578),\n",
       " (\"'\", -0.0971551164984703),\n",
       " ('morning', -0.09750336408615112),\n",
       " ('leave', -0.10003511607646942),\n",
       " ('an', -0.10625870525836945),\n",
       " ('group', -0.11847880482673645),\n",
       " ('voice', -0.1295194774866104),\n",
       " ('take', -0.13242247700691223),\n",
       " ('all', -0.13377778232097626),\n",
       " ('was', -0.13809029757976532)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that are more related to...:\n",
    "w2v_model.wv.most_similar(negative=[\"ukraine\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DT4Rvno2mD65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', 0.4474726915359497),\n",
       " ('kotaku', 0.4321092963218689),\n",
       " ('turmoil', 0.42827194929122925),\n",
       " (\"canada's\", 0.42280954122543335),\n",
       " ('potapova', 0.4215622544288635),\n",
       " ('assault', 0.4203118085861206),\n",
       " ('isolation', 0.41900375485420227),\n",
       " ('rest', 0.4138997495174408),\n",
       " ('potent', 0.40887880325317383),\n",
       " ('rosneft', 0.4036126136779785)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that are more related to...:\n",
    "w2v_model.wv.most_similar(positive=[\"invasion\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XPLDPgzBmQXt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yungblud', 0.42140358686447144),\n",
       " ('adds', 0.41485536098480225),\n",
       " ('gulf', 0.4063607156276703),\n",
       " ('regulator', 0.40560370683670044),\n",
       " ('taliban', 0.4004315137863159)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that are more related to...:\n",
    "w2v_model.wv.most_similar(positive=[\"uk\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'armament' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fSIoF\\Documents\\IA\\NLP\\3- EmbeddingGensim.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fSIoF/Documents/IA/NLP/3-%20EmbeddingGensim.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Training with a word that is not on the vocabulary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fSIoF/Documents/IA/NLP/3-%20EmbeddingGensim.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w2v_model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mmost_similar(negative\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39marmament\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    838\u001b[0m         weight[idx] \u001b[39m=\u001b[39m item[\u001b[39m1\u001b[39m]\n\u001b[0;32m    840\u001b[0m \u001b[39m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_mean_vector(keys, weight, pre_normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, post_normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ignore_missing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    842\u001b[0m all_keys \u001b[39m=\u001b[39m [\n\u001b[0;32m    843\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, _KEY_TYPES) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    844\u001b[0m ]\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(topn, \u001b[39mint\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    516\u001b[0m         total_weight \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(weights[idx])\n\u001b[0;32m    517\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 518\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present in vocabulary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m total_weight \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    521\u001b[0m     mean \u001b[39m=\u001b[39m mean \u001b[39m/\u001b[39m total_weight\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'armament' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# Training with a word that is not on the vocabulary\n",
    "w2v_model.wv.most_similar(negative=[\"armament\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g8UVWe6lFmh"
   },
   "source": [
    "### 5 - View vector grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pDxEVXAivjr9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    \n",
    "from sklearn.manifold import TSNE                   \n",
    "                               \n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  \n",
    "\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  \n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCCXtDpcugmd"
   },
   "outputs": [],
   "source": [
    "# Plotting the embedding in 2D\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(w2v_model)\n",
    "\n",
    "MAX_WORDS=100\n",
    "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMM_SHSaZ9N-"
   },
   "source": [
    "### Alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WivQZ3ZCZ9N_"
   },
   "source": [
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "- Graficarlos.\n",
    "- Obtener conclusiones."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
